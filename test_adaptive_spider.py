#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ™ºèƒ½é€‚é…çˆ¬è™«åŠŸèƒ½
"""

import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from spider.config import SpiderConfig
from spider.core import SpiderCore

def test_adaptive_parsing():
    """æµ‹è¯•æ™ºèƒ½é€‚é…è§£æåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•æ™ºèƒ½é€‚é…çˆ¬è™«åŠŸèƒ½")
    print("=" * 60)
    
    # åˆ›å»ºçˆ¬è™«é…ç½®
    config = SpiderConfig()
    config.MAX_PAGES = 2  # åªæµ‹è¯•2é¡µ
    config.MAX_CONCURRENT_REQUESTS = 2  # é™ä½å¹¶å‘æ•°
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    spider = SpiderCore(config)
    
    # æµ‹è¯•ä¸åŒåˆ†ç±»çš„çˆ¬å–
    test_categories = [
        ("tablegames", "æ¡Œæ¸¸"),
        ("games", "æ¸¸æˆ"),
        ("publishing", "å‡ºç‰ˆ"),
        ("cards", "å¡ç‰Œ"),
        ("toys", "æ½®ç©æ¨¡å‹")
    ]
    
    results = {}
    
    for category, category_name in test_categories:
        print(f"\nğŸ¯ æµ‹è¯•åˆ†ç±»: {category_name} ({category})")
        print("-" * 40)
        
        try:
            # é‡ç½®çˆ¬è™«çŠ¶æ€
            spider.projects_data.clear()
            spider.failed_urls.clear()
            
            # å¼€å§‹çˆ¬å–
            start_time = time.time()
            success = spider.start_crawling(
                start_page=1, 
                end_page=1,  # åªçˆ¬å–ç¬¬ä¸€é¡µè¿›è¡Œæµ‹è¯•
                category=category
            )
            
            elapsed_time = time.time() - start_time
            
            # æ”¶é›†ç»“æœ
            stats = spider.get_crawl_stats()
            results[category] = {
                "success": success,
                "projects_count": len(spider.projects_data),
                "failed_count": len(spider.failed_urls),
                "elapsed_time": elapsed_time,
                "stats": stats
            }
            
            print(f"âœ… çˆ¬å–å®Œæˆ:")
            print(f"   æˆåŠŸ: {success}")
            print(f"   é¡¹ç›®æ•°é‡: {len(spider.projects_data)}")
            print(f"   å¤±è´¥æ•°é‡: {len(spider.failed_urls)}")
            print(f"   è€—æ—¶: {elapsed_time:.2f}ç§’")
            
            # æ˜¾ç¤ºéƒ¨åˆ†é¡¹ç›®ä¿¡æ¯
            if spider.projects_data:
                print(f"   ç¤ºä¾‹é¡¹ç›®:")
                for i, project in enumerate(spider.projects_data[:3]):
                    if len(project) >= 5:
                        print(f"     {i+1}. {project[3][:50]}...")  # é¡¹ç›®åç§°
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            results[category] = {
                "success": False,
                "error": str(e),
                "projects_count": 0,
                "failed_count": 0,
                "elapsed_time": 0
            }
        
        # çŸ­æš‚ä¼‘æ¯é¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(2)
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    total_projects = 0
    successful_categories = 0
    
    for category, category_name in test_categories:
        result = results.get(category, {})
        success = result.get("success", False)
        projects_count = result.get("projects_count", 0)
        elapsed_time = result.get("elapsed_time", 0)
        
        status = "âœ…" if success else "âŒ"
        print(f"{status} {category_name:12} | é¡¹ç›®: {projects_count:3} | è€—æ—¶: {elapsed_time:6.2f}s")
        
        if success:
            successful_categories += 1
            total_projects += projects_count
    
    print("-" * 60)
    print(f"æˆåŠŸåˆ†ç±»: {successful_categories}/{len(test_categories)}")
    print(f"æ€»é¡¹ç›®æ•°: {total_projects}")
    
    # æµ‹è¯•æ•°æ®å®Œæ•´æ€§
    print(f"\nğŸ” æ•°æ®å®Œæ•´æ€§æµ‹è¯•")
    print("-" * 40)
    
    if spider.projects_data:
        sample_project = spider.projects_data[0]
        expected_fields = 34  # é¢„æœŸçš„å­—æ®µæ•°é‡
        actual_fields = len(sample_project)
        
        print(f"é¢„æœŸå­—æ®µæ•°: {expected_fields}")
        print(f"å®é™…å­—æ®µæ•°: {actual_fields}")
        print(f"å®Œæ•´æ€§: {actual_fields/expected_fields*100:.1f}%")
        
        # æ£€æŸ¥å…³é”®å­—æ®µ
        key_fields = {
            "é¡¹ç›®URL": sample_project[1] if len(sample_project) > 1 else "ç¼ºå¤±",
            "é¡¹ç›®ID": sample_project[2] if len(sample_project) > 2 else "ç¼ºå¤±", 
            "é¡¹ç›®åç§°": sample_project[3] if len(sample_project) > 3 else "ç¼ºå¤±",
            "é¡¹ç›®çŠ¶æ€": sample_project[7] if len(sample_project) > 7 else "ç¼ºå¤±",
            "ä½œè€…åç§°": sample_project[11] if len(sample_project) > 11 else "ç¼ºå¤±"
        }
        
        for field_name, field_value in key_fields.items():
            status = "âœ…" if field_value and field_value != "ç¼ºå¤±" and field_value != "none" else "âŒ"
            print(f"{status} {field_name}: {str(field_value)[:30]}...")
    
    # æ€§èƒ½è¯„ä¼°
    print(f"\nâš¡ æ€§èƒ½è¯„ä¼°")
    print("-" * 40)
    
    if results:
        avg_time_per_category = sum(r.get("elapsed_time", 0) for r in results.values()) / len(results)
        avg_projects_per_category = sum(r.get("projects_count", 0) for r in results.values()) / len(results)
        
        print(f"å¹³å‡æ¯åˆ†ç±»è€—æ—¶: {avg_time_per_category:.2f}ç§’")
        print(f"å¹³å‡æ¯åˆ†ç±»é¡¹ç›®æ•°: {avg_projects_per_category:.1f}ä¸ª")
        
        if avg_projects_per_category > 0:
            avg_time_per_project = avg_time_per_category / avg_projects_per_category
            print(f"å¹³å‡æ¯é¡¹ç›®è€—æ—¶: {avg_time_per_project:.2f}ç§’")
    
    return results

def test_specific_category(category: str = "tablegames", pages: int = 3):
    """æµ‹è¯•ç‰¹å®šåˆ†ç±»çš„è¯¦ç»†çˆ¬å–"""
    print(f"\nğŸ¯ è¯¦ç»†æµ‹è¯•åˆ†ç±»: {category}")
    print("=" * 60)
    
    config = SpiderConfig()
    config.MAX_PAGES = pages
    
    spider = SpiderCore(config)
    
    try:
        success = spider.start_crawling(
            start_page=1,
            end_page=pages,
            category=category
        )
        
        print(f"\nğŸ“Š è¯¦ç»†æµ‹è¯•ç»“æœ:")
        print(f"æˆåŠŸ: {success}")
        print(f"é¡¹ç›®æ€»æ•°: {len(spider.projects_data)}")
        print(f"å¤±è´¥URLæ•°: {len(spider.failed_urls)}")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = spider.get_crawl_stats()
        print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        for key, value in stats.items():
            if isinstance(value, (int, float)):
                print(f"  {key}: {value}")
        
        return success
        
    except Exception as e:
        print(f"âŒ è¯¦ç»†æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ æ‘©ç‚¹æ™ºèƒ½é€‚é…çˆ¬è™«æµ‹è¯•")
    print("=" * 60)
    
    # åŸºç¡€é€‚é…æµ‹è¯•
    results = test_adaptive_parsing()
    
    # å¦‚æœåŸºç¡€æµ‹è¯•æˆåŠŸï¼Œè¿›è¡Œè¯¦ç»†æµ‹è¯•
    successful_count = sum(1 for r in results.values() if r.get("success", False))
    
    if successful_count > 0:
        print(f"\nâœ… åŸºç¡€æµ‹è¯•é€šè¿‡ ({successful_count}/{len(results)} ä¸ªåˆ†ç±»æˆåŠŸ)")
        
        # é€‰æ‹©ä¸€ä¸ªæˆåŠŸçš„åˆ†ç±»è¿›è¡Œè¯¦ç»†æµ‹è¯•
        for category, result in results.items():
            if result.get("success", False):
                test_specific_category(category, 2)
                break
    else:
        print(f"\nâŒ åŸºç¡€æµ‹è¯•å¤±è´¥ï¼Œæ‰€æœ‰åˆ†ç±»éƒ½æ— æ³•æ­£å¸¸çˆ¬å–")
        return False
    
    print(f"\nğŸ‰ æ™ºèƒ½é€‚é…çˆ¬è™«æµ‹è¯•å®Œæˆï¼")
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
