# -*- coding: utf-8 -*-
"""
æ€§èƒ½ç›‘æ§å’Œè‡ªåŠ¨è°ƒä¼˜æ¨¡å—
å®æ—¶ç›‘æ§ç³»ç»Ÿæ€§èƒ½å¹¶è‡ªåŠ¨è°ƒæ•´å‚æ•°ä»¥ä¼˜åŒ–æ€§èƒ½
"""

import time
import threading
import psutil
import json
from typing import Dict, Any, List, Optional, Callable
from dataclasses import dataclass, field
from pathlib import Path
import statistics
import queue


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    timestamp: float
    cpu_percent: float
    memory_percent: float
    memory_mb: float
    network_io_bytes: int
    disk_io_bytes: int
    active_threads: int
    request_rate: float
    response_time: float
    error_rate: float
    success_rate: float


@dataclass
class TuningRule:
    """è°ƒä¼˜è§„åˆ™"""
    name: str
    condition: Callable[[PerformanceMetrics], bool]
    action: Callable[[Dict[str, Any]], Dict[str, Any]]
    description: str
    cooldown_seconds: int = 60
    last_applied: float = 0


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, monitoring_interval: float = 10.0):
        self.monitoring_interval = monitoring_interval
        self.metrics_history: List[PerformanceMetrics] = []
        self.max_history_size = 1000
        
        # ç›‘æ§çŠ¶æ€
        self._monitoring = False
        self._monitor_thread = None
        self._lock = threading.RLock()
        
        # æ€§èƒ½åŸºçº¿
        self.baseline_metrics = None
        self.baseline_samples = 10
        
        # å‘Šè­¦é˜ˆå€¼
        self.alert_thresholds = {
            'cpu_percent': 80.0,
            'memory_percent': 85.0,
            'error_rate': 10.0,
            'response_time': 5.0
        }
        
        # å‘Šè­¦å†å²
        self.alerts = []
        self.max_alerts = 100
    
    def start_monitoring(self):
        """å¼€å§‹æ€§èƒ½ç›‘æ§"""
        if self._monitoring:
            return
        
        self._monitoring = True
        self._monitor_thread = threading.Thread(
            target=self._monitoring_loop,
            daemon=True
        )
        self._monitor_thread.start()
        print(f"ğŸ“Š æ€§èƒ½ç›‘æ§å·²å¯åŠ¨ï¼Œç›‘æ§é—´éš”: {self.monitoring_interval}ç§’")
    
    def stop_monitoring(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        self._monitoring = False
        if self._monitor_thread:
            self._monitor_thread.join(timeout=5)
        print("ğŸ“Š æ€§èƒ½ç›‘æ§å·²åœæ­¢")
    
    def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self._monitoring:
            try:
                metrics = self._collect_metrics()
                
                with self._lock:
                    self.metrics_history.append(metrics)
                    
                    # é™åˆ¶å†å²è®°å½•å¤§å°
                    if len(self.metrics_history) > self.max_history_size:
                        self.metrics_history.pop(0)
                
                # æ£€æŸ¥å‘Šè­¦
                self._check_alerts(metrics)
                
                # å»ºç«‹æ€§èƒ½åŸºçº¿
                if not self.baseline_metrics and len(self.metrics_history) >= self.baseline_samples:
                    self._establish_baseline()
                
                time.sleep(self.monitoring_interval)
                
            except Exception as e:
                print(f"âŒ æ€§èƒ½ç›‘æ§é”™è¯¯: {e}")
                time.sleep(self.monitoring_interval)
    
    def _collect_metrics(self) -> PerformanceMetrics:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        # CPUå’Œå†…å­˜ä¿¡æ¯
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        
        # ç½‘ç»œå’Œç£ç›˜I/O
        try:
            net_io = psutil.net_io_counters()
            network_io_bytes = net_io.bytes_sent + net_io.bytes_recv
        except:
            network_io_bytes = 0
        
        try:
            disk_io = psutil.disk_io_counters()
            disk_io_bytes = disk_io.read_bytes + disk_io.write_bytes if disk_io else 0
        except:
            disk_io_bytes = 0
        
        # çº¿ç¨‹æ•°
        active_threads = threading.active_count()
        
        # åº”ç”¨çº§æŒ‡æ ‡ï¼ˆéœ€è¦ä»å…¶ä»–ç»„ä»¶è·å–ï¼‰
        request_rate = self._get_request_rate()
        response_time = self._get_average_response_time()
        error_rate = self._get_error_rate()
        success_rate = 100.0 - error_rate
        
        return PerformanceMetrics(
            timestamp=time.time(),
            cpu_percent=cpu_percent,
            memory_percent=memory.percent,
            memory_mb=memory.used / 1024 / 1024,
            network_io_bytes=network_io_bytes,
            disk_io_bytes=disk_io_bytes,
            active_threads=active_threads,
            request_rate=request_rate,
            response_time=response_time,
            error_rate=error_rate,
            success_rate=success_rate
        )
    
    def _get_request_rate(self) -> float:
        """è·å–è¯·æ±‚é€Ÿç‡ï¼ˆæ¯ç§’è¯·æ±‚æ•°ï¼‰"""
        # ä»ç½‘ç»œä¼˜åŒ–å™¨è·å–ç»Ÿè®¡ä¿¡æ¯
        try:
            from .network_optimizer import get_network_optimizer
            optimizer = get_network_optimizer()
            stats = optimizer.get_network_stats()
            
            # è®¡ç®—æœ€è¿‘çš„è¯·æ±‚é€Ÿç‡
            if len(self.metrics_history) >= 2:
                recent_metrics = self.metrics_history[-2:]
                time_diff = recent_metrics[1].timestamp - recent_metrics[0].timestamp
                if time_diff > 0:
                    return stats['total_requests'] / time_diff
            
            return 0.0
        except:
            return 0.0
    
    def _get_average_response_time(self) -> float:
        """è·å–å¹³å‡å“åº”æ—¶é—´"""
        try:
            from .network_optimizer import get_network_optimizer
            optimizer = get_network_optimizer()
            stats = optimizer.get_network_stats()
            return stats.get('average_response_time', 0.0)
        except:
            return 0.0
    
    def _get_error_rate(self) -> float:
        """è·å–é”™è¯¯ç‡"""
        try:
            from .error_recovery import get_error_recovery_manager
            manager = get_error_recovery_manager()
            report = manager.get_error_report()
            
            total_errors = report['total_errors']
            if total_errors > 0:
                # è®¡ç®—æœ€è¿‘çš„é”™è¯¯ç‡
                recent_errors = len([
                    err for err in report['recent_errors']
                    if time.time() - err['timestamp'] < 300  # æœ€è¿‘5åˆ†é’Ÿ
                ])
                return (recent_errors / total_errors) * 100
            
            return 0.0
        except:
            return 0.0
    
    def _establish_baseline(self):
        """å»ºç«‹æ€§èƒ½åŸºçº¿"""
        recent_metrics = self.metrics_history[-self.baseline_samples:]
        
        self.baseline_metrics = {
            'cpu_percent': statistics.mean(m.cpu_percent for m in recent_metrics),
            'memory_percent': statistics.mean(m.memory_percent for m in recent_metrics),
            'response_time': statistics.mean(m.response_time for m in recent_metrics),
            'request_rate': statistics.mean(m.request_rate for m in recent_metrics)
        }
        
        print(f"ğŸ“Š æ€§èƒ½åŸºçº¿å·²å»ºç«‹: CPU {self.baseline_metrics['cpu_percent']:.1f}%, "
              f"å†…å­˜ {self.baseline_metrics['memory_percent']:.1f}%, "
              f"å“åº”æ—¶é—´ {self.baseline_metrics['response_time']:.2f}s")
    
    def _check_alerts(self, metrics: PerformanceMetrics):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        alerts = []
        
        if metrics.cpu_percent > self.alert_thresholds['cpu_percent']:
            alerts.append(f"CPUä½¿ç”¨ç‡è¿‡é«˜: {metrics.cpu_percent:.1f}%")
        
        if metrics.memory_percent > self.alert_thresholds['memory_percent']:
            alerts.append(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics.memory_percent:.1f}%")
        
        if metrics.error_rate > self.alert_thresholds['error_rate']:
            alerts.append(f"é”™è¯¯ç‡è¿‡é«˜: {metrics.error_rate:.1f}%")
        
        if metrics.response_time > self.alert_thresholds['response_time']:
            alerts.append(f"å“åº”æ—¶é—´è¿‡é•¿: {metrics.response_time:.2f}s")
        
        # è®°å½•å‘Šè­¦
        for alert in alerts:
            alert_info = {
                'timestamp': metrics.timestamp,
                'message': alert,
                'metrics': metrics
            }
            
            with self._lock:
                self.alerts.append(alert_info)
                if len(self.alerts) > self.max_alerts:
                    self.alerts.pop(0)
            
            print(f"âš ï¸ æ€§èƒ½å‘Šè­¦: {alert}")
    
    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        with self._lock:
            if not self.metrics_history:
                return {'message': 'æš‚æ— æ€§èƒ½æ•°æ®'}
            
            recent_metrics = self.metrics_history[-10:]  # æœ€è¿‘10ä¸ªæ•°æ®ç‚¹
            
            return {
                'current_metrics': {
                    'cpu_percent': recent_metrics[-1].cpu_percent,
                    'memory_percent': recent_metrics[-1].memory_percent,
                    'memory_mb': recent_metrics[-1].memory_mb,
                    'active_threads': recent_metrics[-1].active_threads,
                    'request_rate': recent_metrics[-1].request_rate,
                    'response_time': recent_metrics[-1].response_time,
                    'error_rate': recent_metrics[-1].error_rate,
                    'success_rate': recent_metrics[-1].success_rate
                },
                'average_metrics': {
                    'cpu_percent': statistics.mean(m.cpu_percent for m in recent_metrics),
                    'memory_percent': statistics.mean(m.memory_percent for m in recent_metrics),
                    'response_time': statistics.mean(m.response_time for m in recent_metrics),
                    'request_rate': statistics.mean(m.request_rate for m in recent_metrics)
                },
                'baseline_metrics': self.baseline_metrics,
                'recent_alerts': self.alerts[-10:],
                'total_data_points': len(self.metrics_history)
            }


class AutoTuner:
    """è‡ªåŠ¨è°ƒä¼˜å™¨"""
    
    def __init__(self, monitor: PerformanceMonitor):
        self.monitor = monitor
        self.tuning_rules: List[TuningRule] = []
        self.current_config = {}
        self.tuning_history = []
        
        # æ³¨å†Œé»˜è®¤è°ƒä¼˜è§„åˆ™
        self._register_default_rules()
        
        # è°ƒä¼˜çŠ¶æ€
        self._tuning_enabled = True
        self._lock = threading.RLock()
    
    def _register_default_rules(self):
        """æ³¨å†Œé»˜è®¤è°ƒä¼˜è§„åˆ™"""
        # CPUä½¿ç”¨ç‡è¿‡é«˜æ—¶å‡å°‘å¹¶å‘æ•°
        self.add_tuning_rule(
            name="reduce_concurrency_on_high_cpu",
            condition=lambda m: m.cpu_percent > 80,
            action=lambda c: {**c, 'max_concurrent_requests': max(1, c.get('max_concurrent_requests', 5) - 1)},
            description="CPUä½¿ç”¨ç‡è¿‡é«˜æ—¶å‡å°‘å¹¶å‘æ•°",
            cooldown_seconds=120
        )
        
        # å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜æ—¶è§¦å‘åƒåœ¾å›æ”¶
        self.add_tuning_rule(
            name="gc_on_high_memory",
            condition=lambda m: m.memory_percent > 85,
            action=self._trigger_garbage_collection,
            description="å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜æ—¶è§¦å‘åƒåœ¾å›æ”¶",
            cooldown_seconds=60
        )
        
        # å“åº”æ—¶é—´è¿‡é•¿æ—¶å¢åŠ è¯·æ±‚å»¶è¿Ÿ
        self.add_tuning_rule(
            name="increase_delay_on_slow_response",
            condition=lambda m: m.response_time > 5.0,
            action=lambda c: {**c, 'request_delay': (
                c.get('request_delay', (1.0, 3.0))[0] + 0.5,
                c.get('request_delay', (1.0, 3.0))[1] + 1.0
            )},
            description="å“åº”æ—¶é—´è¿‡é•¿æ—¶å¢åŠ è¯·æ±‚å»¶è¿Ÿ",
            cooldown_seconds=180
        )
        
        # é”™è¯¯ç‡è¿‡é«˜æ—¶å‡å°‘è¯·æ±‚é¢‘ç‡
        self.add_tuning_rule(
            name="reduce_rate_on_high_errors",
            condition=lambda m: m.error_rate > 10,
            action=lambda c: {**c, 'request_delay': (
                max(2.0, c.get('request_delay', (1.0, 3.0))[0] * 1.5),
                max(5.0, c.get('request_delay', (1.0, 3.0))[1] * 1.5)
            )},
            description="é”™è¯¯ç‡è¿‡é«˜æ—¶å‡å°‘è¯·æ±‚é¢‘ç‡",
            cooldown_seconds=300
        )
    
    def add_tuning_rule(self, name: str, condition: Callable, action: Callable, 
                       description: str, cooldown_seconds: int = 60):
        """æ·»åŠ è°ƒä¼˜è§„åˆ™"""
        rule = TuningRule(
            name=name,
            condition=condition,
            action=action,
            description=description,
            cooldown_seconds=cooldown_seconds
        )
        
        with self._lock:
            self.tuning_rules.append(rule)
        
        print(f"ğŸ”§ å·²æ·»åŠ è°ƒä¼˜è§„åˆ™: {name}")
    
    def apply_tuning(self, current_config: Dict[str, Any]) -> Dict[str, Any]:
        """åº”ç”¨è‡ªåŠ¨è°ƒä¼˜"""
        if not self._tuning_enabled:
            return current_config
        
        with self._lock:
            if not self.monitor.metrics_history:
                return current_config
            
            latest_metrics = self.monitor.metrics_history[-1]
            new_config = current_config.copy()
            applied_rules = []
            
            for rule in self.tuning_rules:
                # æ£€æŸ¥å†·å´æ—¶é—´
                if time.time() - rule.last_applied < rule.cooldown_seconds:
                    continue
                
                # æ£€æŸ¥æ¡ä»¶
                if rule.condition(latest_metrics):
                    try:
                        new_config = rule.action(new_config)
                        rule.last_applied = time.time()
                        applied_rules.append(rule.name)
                        
                        print(f"ğŸ”§ åº”ç”¨è°ƒä¼˜è§„åˆ™: {rule.name} - {rule.description}")
                        
                    except Exception as e:
                        print(f"âŒ è°ƒä¼˜è§„åˆ™æ‰§è¡Œå¤±è´¥: {rule.name} - {e}")
            
            # è®°å½•è°ƒä¼˜å†å²
            if applied_rules:
                self.tuning_history.append({
                    'timestamp': time.time(),
                    'applied_rules': applied_rules,
                    'old_config': current_config,
                    'new_config': new_config,
                    'metrics': latest_metrics
                })
                
                # é™åˆ¶å†å²è®°å½•å¤§å°
                if len(self.tuning_history) > 100:
                    self.tuning_history.pop(0)
            
            return new_config
    
    def _trigger_garbage_collection(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è§¦å‘åƒåœ¾å›æ”¶"""
        try:
            from .memory_optimizer import get_memory_optimizer
            optimizer = get_memory_optimizer()
            optimizer._force_garbage_collection()
        except:
            import gc
            gc.collect()
        
        return config
    
    def enable_tuning(self):
        """å¯ç”¨è‡ªåŠ¨è°ƒä¼˜"""
        self._tuning_enabled = True
        print("ğŸ”§ è‡ªåŠ¨è°ƒä¼˜å·²å¯ç”¨")
    
    def disable_tuning(self):
        """ç¦ç”¨è‡ªåŠ¨è°ƒä¼˜"""
        self._tuning_enabled = False
        print("ğŸ”§ è‡ªåŠ¨è°ƒä¼˜å·²ç¦ç”¨")
    
    def get_tuning_report(self) -> Dict[str, Any]:
        """è·å–è°ƒä¼˜æŠ¥å‘Š"""
        with self._lock:
            return {
                'tuning_enabled': self._tuning_enabled,
                'total_rules': len(self.tuning_rules),
                'rules': [
                    {
                        'name': rule.name,
                        'description': rule.description,
                        'last_applied': rule.last_applied,
                        'cooldown_seconds': rule.cooldown_seconds
                    }
                    for rule in self.tuning_rules
                ],
                'recent_tuning_history': self.tuning_history[-10:],
                'total_tuning_actions': len(self.tuning_history)
            }


# å…¨å±€æ€§èƒ½è°ƒä¼˜å™¨
_global_performance_tuner = None
_tuner_lock = threading.Lock()


def get_performance_tuner() -> AutoTuner:
    """è·å–å…¨å±€æ€§èƒ½è°ƒä¼˜å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _global_performance_tuner
    
    if _global_performance_tuner is None:
        with _tuner_lock:
            if _global_performance_tuner is None:
                monitor = PerformanceMonitor()
                _global_performance_tuner = AutoTuner(monitor)
                monitor.start_monitoring()
    
    return _global_performance_tuner
