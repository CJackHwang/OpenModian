# -*- coding: utf-8 -*-
"""
çˆ¬è™«æœåŠ¡å±‚
å°è£…çˆ¬è™«ç›¸å…³çš„ä¸šåŠ¡é€»è¾‘
"""

import uuid
import threading
from typing import Dict, Any, Optional
from spider.core import SpiderCore
from spider.config import SpiderConfig
from core.monitors import WebSpiderMonitor, ScheduledTaskMonitor
from core.managers import TaskManager, InstanceManager
from core.exceptions import TaskException, ConfigException


class SpiderService:
    """çˆ¬è™«æœåŠ¡ - å°è£…çˆ¬è™«ä¸šåŠ¡é€»è¾‘"""
    
    def __init__(self, db_manager, task_scheduler=None, socketio=None):
        self.db_manager = db_manager
        self.task_scheduler = task_scheduler
        self.socketio = socketio
        
        # åˆå§‹åŒ–ç®¡ç†å™¨
        self.task_manager = TaskManager()
        self.instance_manager = InstanceManager()
    
    def create_crawl_task(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºçˆ¬è™«ä»»åŠ¡"""
        from core.logging import log_spider, log_system

        # è®°å½•ä»»åŠ¡åˆ›å»ºè¯·æ±‚
        log_system('info', 'æ”¶åˆ°çˆ¬è™«ä»»åŠ¡åˆ›å»ºè¯·æ±‚', 'spider-service')
        log_spider('info', f'ä»»åŠ¡é…ç½®: é¡µé¢èŒƒå›´={config.get("start_page", 1)}-{config.get("end_page", 10)}, åˆ†ç±»={config.get("category", "all")}', 'spider-service')
        log_spider('info', f'å¹¶å‘è®¾ç½®: {config.get("max_concurrent", 3)}, å»¶è¿ŸèŒƒå›´={config.get("delay_min", 1)}-{config.get("delay_max", 3)}ç§’', 'spider-service')

        # æ¸…ç†æ—§ä»»åŠ¡
        cleaned_count = self.cleanup_old_tasks()
        if cleaned_count > 0:
            log_system('info', f'æ¸…ç†äº† {cleaned_count} ä¸ªå·²å®Œæˆçš„æ—§ä»»åŠ¡', 'spider-service')

        # æ£€æŸ¥æ˜¯å¦ä¸ºå®šæ—¶ä»»åŠ¡
        if config.get('is_scheduled', False):
            log_spider('info', f'åˆ›å»ºå®šæ—¶ä»»åŠ¡ï¼Œæ‰§è¡Œé—´éš”: {config.get("schedule_interval", 3600)}ç§’', 'spider-service')
            return self._create_scheduled_task(config)
        else:
            log_spider('info', 'åˆ›å»ºå³æ—¶æ‰§è¡Œä»»åŠ¡', 'spider-service')
            return self._create_regular_task(config)
    
    def _create_scheduled_task(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºå®šæ—¶ä»»åŠ¡"""
        if not self.task_scheduler:
            raise TaskException("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨æœªåˆå§‹åŒ–")
        
        schedule_interval = max(5, config.get('schedule_interval', 3600))
        task_name = f"å®šæ—¶çˆ¬å–_{config.get('category', 'all')}_{config.get('start_page', 1)}-{config.get('end_page', 10)}"
        
        try:
            task_id = self.task_scheduler.add_scheduled_task(
                name=task_name,
                config=config,
                interval_seconds=schedule_interval
            )
            
            return {
                'task_id': task_id,
                'message': f'å®šæ—¶ä»»åŠ¡å·²åˆ›å»ºï¼Œæ‰§è¡Œé—´éš”: {schedule_interval}ç§’',
                'is_scheduled': True
            }
        except Exception as e:
            raise TaskException(f"åˆ›å»ºå®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}")
    
    def _create_regular_task(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºæ™®é€šä»»åŠ¡"""
        from core.logging import log_spider, log_system

        task_id = str(uuid.uuid4())
        log_spider('info', f'ç”Ÿæˆä»»åŠ¡ID: {task_id}', 'spider-service')

        # åˆ›å»ºçˆ¬è™«é…ç½®
        spider_config = self._build_spider_config(config)
        log_spider('debug', f'çˆ¬è™«é…ç½®æ„å»ºå®Œæˆ: å¹¶å‘={spider_config.MAX_CONCURRENT_REQUESTS}, å»¶è¿Ÿ={spider_config.REQUEST_DELAY}', 'spider-service')

        # åˆ›å»ºç›‘æ§å™¨ - ä¸åŸç‰ˆæœ¬è°ƒç”¨æ–¹å¼å®Œå…¨ä¸€è‡´
        monitor = WebSpiderMonitor(task_id)
        log_system('debug', f'åˆ›å»ºä»»åŠ¡ç›‘æ§å™¨: {task_id}', 'spider-service')

        # è®¾ç½®socketioå®ä¾‹ä»¥æ”¯æŒWebSocketé€šä¿¡
        if self.socketio:
            monitor.set_socketio(self.socketio)
            log_system('debug', 'WebSocketé€šä¿¡å·²é…ç½®', 'spider-service')

        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        spider = SpiderCore(spider_config, web_monitor=monitor, db_manager=self.db_manager)
        log_spider('info', 'çˆ¬è™«æ ¸å¿ƒå®ä¾‹åˆ›å»ºå®Œæˆ', 'spider-service')

        # ä¿å­˜å®ä¾‹å’Œä»»åŠ¡
        self.instance_manager.add_instance(task_id, spider)
        self.task_manager.add_task(task_id, monitor, config)
        log_system('debug', f'ä»»åŠ¡å®ä¾‹å·²æ³¨å†Œåˆ°ç®¡ç†å™¨: {task_id}', 'spider-service')

        # ä¿å­˜ä»»åŠ¡åˆ°æ•°æ®åº“
        self.db_manager.save_crawl_task(task_id, config)
        log_system('info', f'ä»»åŠ¡ä¿¡æ¯å·²ä¿å­˜åˆ°æ•°æ®åº“: {task_id}', 'spider-service')

        # å¯åŠ¨çˆ¬è™«çº¿ç¨‹
        thread = threading.Thread(
            target=self._run_spider_task,
            args=(task_id, spider, monitor, config)
        )
        thread.daemon = True
        thread.start()
        log_spider('info', f'çˆ¬è™«ä»»åŠ¡çº¿ç¨‹å·²å¯åŠ¨: {task_id}', 'spider-service')

        self.task_manager.update_task_thread(task_id, thread)

        log_system('info', f'çˆ¬è™«ä»»åŠ¡åˆ›å»ºå®Œæˆå¹¶å¼€å§‹æ‰§è¡Œ: {task_id}', 'spider-service')

        return {
            'task_id': task_id,
            'message': 'çˆ¬è™«ä»»åŠ¡å·²å¯åŠ¨',
            'is_scheduled': False
        }
    
    def _build_spider_config(self, config: Dict[str, Any]) -> SpiderConfig:
        """æ„å»ºçˆ¬è™«é…ç½®"""
        spider_config = SpiderConfig()
        
        # æ›´æ–°é…ç½®å‚æ•°
        if 'max_concurrent' in config:
            spider_config.MAX_CONCURRENT_REQUESTS = int(config['max_concurrent'])
        if 'delay_min' in config and 'delay_max' in config:
            spider_config.REQUEST_DELAY = (float(config['delay_min']), float(config['delay_max']))
        
        return spider_config
    
    def _run_spider_task(self, task_id: str, spider: SpiderCore,
                        monitor: WebSpiderMonitor, config: Dict[str, Any]) -> None:
        """è¿è¡Œçˆ¬è™«ä»»åŠ¡"""
        from core.logging import log_spider, log_system

        try:
            log_spider('info', f'å¼€å§‹æ‰§è¡Œçˆ¬è™«ä»»åŠ¡: {task_id}', 'spider-task')
            log_spider('info', f'ä»»åŠ¡å‚æ•°: é¡µé¢{config.get("start_page", 1)}-{config.get("end_page", 10)}, åˆ†ç±»={config.get("category", "all")}', 'spider-task')

            monitor.add_log('info', f'å¼€å§‹çˆ¬å–ä»»åŠ¡ {task_id}')
            monitor.update_stats(status='running')

            # è®¾ç½®è¿›åº¦å›è°ƒ
            def progress_callback(current_page=0, total_pages=0, total_projects=0,
                                completed_projects=0, project_progress=0):
                # è®°å½•è¯¦ç»†çš„è¿›åº¦ä¿¡æ¯
                log_spider('debug', f'ä»»åŠ¡è¿›åº¦æ›´æ–°: é¡µé¢{current_page}/{total_pages}, é¡¹ç›®{completed_projects}/{total_projects} ({project_progress:.1f}%)', 'spider-task')
                monitor.update_progress(current_page, total_pages, total_projects,
                                      completed_projects, project_progress)

            spider.set_progress_callback(progress_callback)
            log_system('debug', f'è¿›åº¦å›è°ƒå·²è®¾ç½®: {task_id}', 'spider-task')

            # å¯åŠ¨çˆ¬è™«
            log_spider('info', f'å¯åŠ¨çˆ¬è™«æ ¸å¿ƒå¼•æ“: {task_id}', 'spider-task')

            # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³æ³¨åˆ—è¡¨
            watched_project_ids = config.get('watched_project_ids', [])
            if config.get('include_watch_list', False) and watched_project_ids:
                log_spider('info', f'åŒ…å«å…³æ³¨åˆ—è¡¨é¡¹ç›®: {len(watched_project_ids)}ä¸ª', 'spider-task')

            success = spider.start_crawling(
                start_page=int(config.get('start_page', 1)),
                end_page=int(config.get('end_page', 10)),
                category=config.get('category', 'all'),
                task_id=task_id,
                watched_project_ids=watched_project_ids if config.get('include_watch_list', False) else None
            )

            log_spider('info', f'çˆ¬è™«å¼•æ“æ‰§è¡Œå®Œæˆ: {task_id}, æˆåŠŸ={success}', 'spider-task')
            self._handle_task_completion(task_id, spider, monitor, success)

        except Exception as e:
            log_spider('error', f'çˆ¬è™«ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {task_id}, é”™è¯¯={str(e)}', 'spider-task')
            self._handle_task_error(task_id, monitor, str(e))
    
    def _handle_task_completion(self, task_id: str, spider: SpiderCore, 
                               monitor: WebSpiderMonitor, success: bool) -> None:
        """å¤„ç†ä»»åŠ¡å®Œæˆ"""
        total_saved = getattr(spider, 'saved_count', 0)
        total_found = len(spider.projects_data) if hasattr(spider, 'projects_data') else 0
        
        if success and not spider.is_stopped():
            monitor.add_log('success', f'ğŸ‰ çˆ¬å–ä»»åŠ¡å®Œæˆï¼å‘ç° {total_found} ä¸ªé¡¹ç›®ï¼ŒæˆåŠŸä¿å­˜ {total_saved} æ¡æ•°æ®åˆ°æ•°æ®åº“')
            status = 'completed'
        elif spider.is_stopped():
            monitor.add_log('warning', f'â¹ï¸ ä»»åŠ¡è¢«ç”¨æˆ·åœæ­¢ï¼Œå·²ä¿å­˜ {total_saved} æ¡æ•°æ®åˆ°æ•°æ®åº“ï¼ˆå…±å‘ç° {total_found} ä¸ªé¡¹ç›®ï¼‰')
            status = 'stopped'
        else:
            monitor.add_log('error', 'âŒ çˆ¬å–ä»»åŠ¡å¤±è´¥')
            status = 'failed'
        
        # æ›´æ–°ç»Ÿè®¡å’ŒçŠ¶æ€
        stats = {
            'projects_found': total_found,
            'projects_processed': total_saved
        }
        monitor.update_stats(projects_found=total_found, projects_processed=total_saved, status=status)
        self.db_manager.update_task_status(task_id, status, stats)
        
        # å»¶è¿Ÿæ¸…ç†
        self._schedule_task_cleanup(task_id)
    
    def _handle_task_error(self, task_id: str, monitor: WebSpiderMonitor, error_msg: str) -> None:
        """å¤„ç†ä»»åŠ¡é”™è¯¯"""
        monitor.add_log('error', f'çˆ¬å–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {error_msg}')
        monitor.update_stats(status='error')
        self.db_manager.update_task_status(task_id, 'error')
        self._schedule_task_cleanup(task_id)
    
    def _schedule_task_cleanup(self, task_id: str) -> None:
        """å®‰æ’ä»»åŠ¡æ¸…ç†"""
        def delayed_cleanup():
            import time
            time.sleep(5)  # ç­‰å¾…5ç§’è®©å‰ç«¯æ˜¾ç¤ºå®ŒæˆçŠ¶æ€
            self.cleanup_task(task_id)
        
        cleanup_thread = threading.Thread(target=delayed_cleanup)
        cleanup_thread.daemon = True
        cleanup_thread.start()
    
    def stop_task(self, task_id: str) -> bool:
        """åœæ­¢ä»»åŠ¡"""
        # è·å–ä»»åŠ¡ä¿¡æ¯
        task_info = self.task_manager.get_task(task_id)
        if not task_info:
            return False

        # åœæ­¢çˆ¬è™«å®ä¾‹
        success = self.instance_manager.stop_instance(task_id)

        if success:
            # æ›´æ–°ç›‘æ§å™¨çŠ¶æ€ï¼ˆä¸åŸç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
            monitor = task_info['monitor']
            monitor.add_log('warning', 'ç”¨æˆ·è¯·æ±‚åœæ­¢ä»»åŠ¡')
            monitor.update_stats(status='stopped')

            # æ›´æ–°æ•°æ®åº“ä»»åŠ¡çŠ¶æ€
            self.db_manager.update_task_status(task_id, 'stopped')

            # å®‰æ’å»¶è¿Ÿæ¸…ç†
            self._schedule_task_cleanup(task_id)

        return success
    
    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        task_info = self.task_manager.get_task(task_id)
        if task_info:
            return task_info['monitor'].get_stats()
        return None
    
    def cleanup_task(self, task_id: str) -> None:
        """æ¸…ç†å•ä¸ªä»»åŠ¡"""
        self.instance_manager.remove_instance(task_id)
        self.task_manager.remove_task(task_id)
    
    def cleanup_old_tasks(self) -> int:
        """æ¸…ç†æ—§ä»»åŠ¡"""
        # å…ˆæ¸…ç†å®ä¾‹ç®¡ç†å™¨ä¸­å¯¹åº”çš„å®ä¾‹
        completed_tasks = self.task_manager.get_tasks_by_status('completed')
        failed_tasks = self.task_manager.get_tasks_by_status('failed')
        stopped_tasks = self.task_manager.get_tasks_by_status('stopped')
        error_tasks = self.task_manager.get_tasks_by_status('error')
        
        all_cleanup_tasks = {**completed_tasks, **failed_tasks, **stopped_tasks, **error_tasks}
        
        for task_id in all_cleanup_tasks.keys():
            self.instance_manager.remove_instance(task_id)
        
        # ç„¶åæ¸…ç†ä»»åŠ¡ç®¡ç†å™¨
        return self.task_manager.cleanup_completed_tasks()
    
    def get_all_tasks(self) -> Dict[str, Dict[str, Any]]:
        """è·å–æ‰€æœ‰ä»»åŠ¡"""
        return self.task_manager.get_all_tasks()
