# 摩点爬虫Web UI使用指南

## 🌟 功能特性

### 📊 **可视化工作流管理**
- **实时监控**: 爬取进度、统计数据、错误信息实时更新
- **任务管理**: 启动、停止、监控多个爬虫任务
- **配置界面**: 可视化配置爬虫参数
- **结果下载**: 一键下载爬取结果

### 🎯 **核心功能**
- ✅ **实时进度监控** - 进度条显示爬取进度
- ✅ **实时日志查看** - 彩色日志实时显示
- ✅ **任务状态管理** - 运行中/已完成/失败状态
- ✅ **爬虫停止控制** - 一键停止正在运行的爬虫任务
- ✅ **参数配置** - 页面范围、分类、并发数等
- ✅ **结果下载** - Excel/CSV/JSON格式
- ✅ **历史任务** - 查看所有历史任务记录
- ✅ **数据库管理** - 自动保存和管理爬取数据
- ✅ **时间分类** - 按日/周/月对数据进行分类
- ✅ **数据去重** - 智能检测和过滤重复数据
- ✅ **统计分析** - 实时数据库统计和分析

## 🚀 快速开始

### 1. 启动Web UI

```bash
# 方法1: 使用启动脚本（推荐）
python3 start_web_ui.py

# 方法2: 手动启动
cd web_ui
pip install -r requirements.txt
python3 app.py
```

### 2. 访问界面

打开浏览器访问: **http://localhost:5000**

### 3. 配置爬虫参数

在左侧控制面板配置：
- **页面范围**: 起始页和结束页
- **项目分类**: 选择要爬取的分类
- **并发数**: 同时爬取的线程数（建议1-5）
- **请求延迟**: 避免被封IP的延迟设置

### 4. 开始爬取

点击"开始爬取"按钮，系统将：
- 生成唯一任务ID
- 自动保存任务到数据库
- 实时显示爬取进度
- 更新统计信息
- 显示实时日志
- 自动保存爬取结果到数据库

### 5. 停止爬取

在爬取过程中，可以：
- 点击"停止爬取"按钮立即停止任务
- 系统会安全地停止爬虫线程
- 已爬取的数据会保存到数据库
- 任务状态更新为"已停止"

### 6. 数据库管理

系统提供完整的数据库管理功能：
- **自动保存**: 爬取的数据自动保存到SQLite数据库
- **智能去重**: 基于项目ID和关键信息自动去重
- **时间分类**: 按日/周/月/年对数据进行分类
- **统计分析**: 实时显示总项目数、今日新增、本周新增等
- **数据导出**: 支持按时间周期导出Excel文件

## 🎨 界面介绍

### 📋 **左侧控制面板**

#### 爬虫配置
- **起始页/结束页**: 设置爬取的页面范围
- **项目分类**: 选择特定分类或全部分类
- **并发数**: 控制爬取速度和服务器压力
- **延迟设置**: 防止被反爬虫机制封禁

#### 系统状态
- **活跃任务**: 当前正在运行的任务数
- **已完成**: 成功完成的任务数
- **失败**: 失败的任务数

### 📊 **右侧监控面板**

#### 当前任务
- **进度条**: 可视化显示爬取进度
- **统计信息**: 页面数、项目数、错误数
- **操作按钮**: 下载结果、清空日志

#### 实时日志
- **彩色日志**: 不同级别用不同颜色显示
- **时间戳**: 每条日志都有精确时间
- **自动滚动**: 新日志自动滚动到底部

#### 数据库管理
- **统计概览**: 显示总项目数、今日新增、本周新增
- **时间筛选**: 选择查看今日/本周/本月/全部数据
- **数据预览**: 实时预览数据库中的项目信息
- **数据导出**: 按时间周期导出Excel文件
- **自动去重**: 智能检测重复数据并自动过滤

#### 历史任务
- **任务列表**: 显示所有历史任务
- **状态标识**: 运行中/已完成/失败/已停止状态
- **快速下载**: 点击下载按钮获取结果
- **数据库记录**: 所有任务自动记录到数据库

## ⚙️ 配置说明

### 🔧 **爬虫参数**

| 参数 | 说明 | 推荐值 | 注意事项 |
|------|------|--------|----------|
| **起始页** | 开始爬取的页面 | 1 | 必须 ≤ 结束页 |
| **结束页** | 结束爬取的页面 | 10 | 建议小批量测试 |
| **项目分类** | 要爬取的分类 | 全部分类 | 可选择特定分类 |
| **并发数** | 同时运行的线程数 | 3 | 1-5，过高可能被封IP |
| **最小延迟** | 请求间最小间隔 | 1秒 | 防止请求过快 |
| **最大延迟** | 请求间最大间隔 | 3秒 | 随机延迟更安全 |

### 📂 **输出格式**

爬虫支持多种输出格式：
- **Excel (.xlsx)**: 包含完整数据和格式
- **CSV (.csv)**: 纯文本格式，易于处理
- **JSON (.json)**: 结构化数据格式
- **SQLite数据库**: 自动保存到database/modian_data.db

### 🗄️ **数据库结构**

系统使用SQLite数据库存储数据，包含以下表：

#### projects表（项目数据）
- 项目基本信息：ID、名称、链接、图片
- 作者信息：姓名、链接、头像
- 众筹信息：已筹金额、目标金额、支持者数
- 时间信息：开始时间、结束时间、爬取时间
- 状态信息：项目状态、回报信息等

#### crawl_tasks表（爬取任务）
- 任务信息：任务ID、配置参数
- 时间信息：开始时间、结束时间
- 统计信息：发现项目数、处理项目数、错误数
- 状态信息：运行中/已完成/失败/已停止

## 🔍 **实时监控**

### 📈 **进度监控**
- **百分比进度**: 精确显示完成百分比
- **页面计数**: 已爬取页面数/总页面数
- **项目统计**: 发现项目数/已处理项目数
- **错误统计**: 实时显示错误数量

### 📝 **日志系统**
- **信息日志** (蓝色): 一般信息
- **成功日志** (绿色): 成功操作
- **警告日志** (黄色): 警告信息
- **错误日志** (红色): 错误信息

### 🔄 **WebSocket实时通信**
- 使用WebSocket技术实现实时数据更新
- 连接状态显示在右上角
- 断线自动重连机制

## 📥 **结果下载**

### 下载方式
1. **当前任务**: 点击"下载结果"按钮
2. **历史任务**: 在历史任务表格中点击下载图标

### 文件命名
```
modian_projects_YYYYMMDD_HHMMSS_final.xlsx
modian_projects_YYYYMMDD_HHMMSS_final.csv
modian_projects_YYYYMMDD_HHMMSS_final.json
```

## 🛠️ **技术架构**

### 前端技术
- **Bootstrap 5**: 响应式UI框架
- **Socket.IO**: 实时通信
- **原生JavaScript**: 无框架依赖

### 后端技术
- **Flask**: Web框架
- **Flask-SocketIO**: WebSocket支持
- **多线程**: 后台任务处理

### 数据流程
```
用户配置 → Flask API → 爬虫任务 → 实时更新 → WebSocket → 前端显示
```

## 🚨 **注意事项**

### ⚠️ **使用建议**
1. **小批量测试**: 首次使用建议爬取1-5页测试
2. **合理延迟**: 设置适当的请求延迟避免被封IP
3. **监控日志**: 关注错误日志，及时调整参数
4. **网络稳定**: 确保网络连接稳定

### 🔒 **安全提醒**
- 仅在本地网络使用，不要暴露到公网
- 遵守网站的robots.txt和使用条款
- 合理控制爬取频率，避免对服务器造成压力

## 🐛 **故障排除**

### 常见问题

**Q: Web UI无法启动？**
A: 检查Python版本和依赖安装：
```bash
python3 --version  # 确保Python 3.7+
pip install -r web_ui/requirements.txt
```

**Q: 连接状态显示断开？**
A: 刷新页面或检查网络连接

**Q: 任务卡住不动？**
A: 查看日志信息，可能是网络问题或被反爬虫

**Q: 下载文件为空？**
A: 确保任务已完成且有数据产出

## 📞 **技术支持**

如遇到问题，请检查：
1. 控制台错误信息
2. 浏览器开发者工具
3. 服务器日志输出

---

## 🎉 **开始使用**

现在你可以通过现代化的Web界面轻松管理摩点爬虫任务了！

```bash
python3 start_web_ui.py
```

访问 **http://localhost:5000** 开始你的爬虫之旅！ 🚀
